{"pages":[],"posts":[{"title":"안녕하세요","text":"안녕하세요첫 포스팅","link":"/2021/07/16/%EC%95%88%EB%85%95%ED%95%98%EC%84%B8%EC%9A%94/"},{"title":"Linear Regression의 Hypothesis 와 cost 설명[1]","text":"[본 포스팅은 YouTube Sung Kim 님의 자료를 바탕으로 제작 되었음] 1. Linear Regression이란?Linear Regression은 1차원 형태의 선형 데이터를 가지고 값(정답)을 예측하는 방법이다. 간단히 예를 들어 설명하면, 그림 1. 과 같은 x, y에 대한 데이터가 있다 하자. 즉, x가 1이면 y는 1이고, x가 2면 y는 2, x가 3이면 y는 3이 된다. 이를 그래프로 나타내면 그림 2. 와 같다.그리고 여기서 x,y의 데이터는 학습 데이터이다. 이 데이터를 가지고 어떤 x가 주어졌을 때, y를 예측하는 것이다.그림 1. 그림 2. 2. 어떻게 예측할까?기본적으로 ‘예측’ 이라는 것을 하기 위해서는, ‘학습’을 해야된다. 그렇다면 여기서 ‘학습’이라는 것은 무엇을 의미하는걸까?결론부터 말하면, Hypothesis(가설)을 세워서 ‘Cost Function’ 이라는 것을 통해 실제 데이터와의 차이를 줄여나가는 것을 말한다.그림으로 조금 더 쉽게 설명하면,아래 그림 3. 에서 파란색 선은 테스트 데이터를 나타내고, 노란색과 빨간색은 하나의 가설이 된다.파란색과 노란색의 간격, 또는 파란색과 빨간색의 간격이 곧 가설과 실제 테스트 데이터의 차이가 된다.이 차이를 줄여나가면서 가설을 조금씩 바꾸는 과정을 ‘학습’이라고 보면 된다. 그림 3. 그럼 이러한 설명을 수식으로 나타내보면,노란색과 빨간색의 가설은 각각 1차 방정식에 의해 아래와 같이 나타낼 수 있다.H(x) = Wx + b그러면 W와 b의 값에 따라 선의 모양이 정해지는데,이때 선의 모양이 파란색과 일치하도록 최대한 가깝게 W와 b를 조절해 나가는 것이 ‘학습’이다. 그렇다면, 테스트 데이터와 가설 데이터의 차이를 어떻게 구할 수 있을까?아래 그림 4. 를 통해 설명하면,파란색 선을 가설이라 하고, 각 점을 실제 테스트 데이터라고 해보자 그림 4. 이때 가설과 데스트 데이터의 차이는 아래와 같이 나타낼 수 있다.H(x) - y H(x) : 가설의 y값y : 테스트 데이터의 y 값 이때 차이는 음수(-)가 될 수 있기 때문에 각 차이를 제곱하여 나타낸다.(H(x) - y)^2 그렇다면 이 차이 값들의 합이 적을수록 테스트 데이터에 가까워진다고 할 수 있다.이처럼, 각 점들의 차이 제곱의 합을 구하는 것을 Cost Function 또는 Loss Function이라 부른다. 그림 5. 와 같이 각 차이의 제곱의 평균을 구해서 최종적인 ‘Cost’를 구한다. 그림 5. 위 그림 5.에서 H(x)은 가설의 값이다. 처음 우리가 세운 H(x) = Wx + b 이기 때문에위 수식에 그대로 대입해보면, 그림 6.과 같다 그림 6. 최종 cost(W,b)에서 W와 b의 값을 조절해나가면서 최소 값을 구하는 것이 ‘학습’ 이라 한다. 이것을 Formal하게 나타내면 최종적으로 아래와 같이 나타낼 수 있다. 그림 7.","link":"/2021/07/17/hexo/"}],"tags":[{"name":"Tag1","slug":"Tag1","link":"/tags/Tag1/"},{"name":"Tag2","slug":"Tag2","link":"/tags/Tag2/"},{"name":"Tag3","slug":"Tag3","link":"/tags/Tag3/"}],"categories":[{"name":"ML","slug":"ML","link":"/categories/ML/"},{"name":"Start","slug":"Start","link":"/categories/Start/"},{"name":"Sung Kim","slug":"ML/Sung-Kim","link":"/categories/ML/Sung-Kim/"}]}